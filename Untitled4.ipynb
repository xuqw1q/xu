{"cells":[{"cell_type":"code","source":["!pip install keras-tqdm\n","!pip install torchinfo\n","\n","import numpy as np\n","from numpy import linalg as la\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.models as models\n","from keras_tqdm import TQDMNotebookCallback\n","import pickle, random\n","import os,sys\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from sklearn.preprocessing import label_binarize\n","from tensorflow.keras.callbacks import TensorBoard\n","import h5py\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","from matplotlib import pyplot\n","from matplotlib.font_manager import FontProperties\n","from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n","import matplotlib\n","\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import h5py\n","import json\n","from matplotlib import pyplot as plt\n","import torch\n","from torch import nn\n","from torchinfo import summary\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import trange, tqdm\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","import pickle, random\n","import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from sklearn.preprocessing import label_binarize\n","import seaborn as sns"],"metadata":{"id":"s-ZtAmG1BvLv","executionInfo":{"status":"aborted","timestamp":1718194841047,"user_tz":-480,"elapsed":4,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"id":"s-ZtAmG1BvLv","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e051ae2","executionInfo":{"status":"aborted","timestamp":1718194841432,"user_tz":-480,"elapsed":389,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["n_channels=2\n","batch_size=32\n","# Number of frames per snr/modulation combination for train,valid and test data\n","nf_train = 1024\n","nf_valid = 512\n","nf_test = 512"],"id":"3e051ae2"},{"cell_type":"code","execution_count":null,"id":"0afffb9a","metadata":{"id":"0afffb9a","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":390,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["def dataset_split(data,\n","                   modulations_classes,\n","                   modulations,snrs,\n","                   target_modulations,\n","                   mode,\n","                   target_snrs,train_proportion,\n","                   valid_proportion,\n","                   test_proportion,\n","                   seed=48):\n","    np.random.seed(seed)\n","    train_split_index = int(train_proportion*596)\n","    valid_split_index = int((valid_proportion+train_proportion)*596)\n","    test_split_index = int((test_proportion+valid_proportion+train_proportion)*596)\n","    X_output=[]\n","    Y_output=[]\n","    Z_output=[]\n","\n","    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]\n","\n","    for modu in  target_modulation_indices:\n","        for snr in target_snrs:\n","            snr_modu_indices = np.where((modulations==modu) & (snrs==snr))[0]\n","\n","            np.random.shuffle(snr_modu_indices)\n","            train, valid, test, remaining = np.split(snr_modu_indices, [train_split_index,valid_split_index,test_split_index])\n","            if mode=='train':\n","                X_output.append(data[np.sort(train)])\n","                Y_output.append(modulations[np.sort(train)])\n","                Z_output.append(snrs[np.sort(train)])\n","            elif mode=='valid':\n","                X_output.append(data[np.sort(valid)])\n","                Y_output.append(modulations[np.sort(valid)])\n","                Z_output.append(snrs[np.sort(valid)])\n","            elif mode =='test':\n","                X_output.append(data[np.sort(test)])\n","                Y_output.append(modulations[np.sort(test)])\n","                Z_output.append(snrs[np.sort(test)])\n","            else:\n","                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test')\n","    X_array = np.vstack(X_output)\n","    Y_array = np.concatenate(Y_output)\n","    Z_array = np.concatenate(Z_output)\n","    for index,value in enumerate(np.unique(np.copy(Y_array))):\n","        Y_array[Y_array==value]=index\n","    return X_array, Y_array, Z_array\n","\n","\n","\n","class RadioML18Dataset(Dataset):\n","    def __init__(self, mode: str,seed=48,):\n","        super(RadioML18Dataset, self).__init__()\n","\n","        # load data\n","        hdf5_file = h5py.File(\"datasets/GOLD_XYZ_OSC.0001_1024.hdf5\",  'r')\n","        self.modulation_classes = json.load(open(\"datasets/classes-fixed.json\", 'r'))\n","        self.X = hdf5_file['X']\n","        self.Y = np.argmax(hdf5_file['Y'], axis=1)\n","        self.Z = hdf5_file['Z'][:, 0]\n","\n","        #train_proportion=(24*26*nf_train)/self.X.shape[0]\n","        #test_proportion=(24*26*nf_test)/self.X.shape[0]\n","#         target_modulations =['OOK','4ASK','8ASK','BPSK', 'QPSK','8PSK','16PSK','32PSK','16APSK', '32APSK','64APSK','128APSK',\n","   #    '16QAM', '32QAM','64QAM','128QAM','256QAM','AM-SSB-WC','AM-SSB-SC','AM-DSB-WC',\n","     #   'AM-DSB-SC','FM', 'GMSK','OQPSK']\n","        train_proportion=(24*26*nf_train)/self.X.shape[0]\n","        valid_proportion=(24*26*nf_valid)/self.X.shape[0]\n","        test_proportion=(24*26*nf_test)/self.X.shape[0]\n","        # Target modulation class and snr\n","        self.target_modulations = ['OOK','4ASK','8ASK','8PSK','16PSK','32PSK','16APSK', '32APSK','64APSK','128APSK',\n","       '16QAM', '32QAM','64QAM','128QAM','256QAM','AM-SSB-WC','AM-SSB-SC','AM-DSB-WC',\n","       ]\n","\n","\n","        self.target_snrs = np.unique(self.Z)\n","\n","\n","        self.X_data, self.Y_data, self.Z_data = dataset_split(\n","                                                                  data = self.X,\n","                                                                  modulations_classes = self.modulation_classes,\n","                                                                  modulations = self.Y,\n","                                                                  snrs = self.Z,\n","                                                                  mode = mode,\n","                                                                  train_proportion = train_proportion,\n","                                                                  valid_proportion = valid_proportion,\n","                                                                  test_proportion = test_proportion,\n","                                                                  target_modulations = self.target_modulations,\n","                                                                  target_snrs  = self.target_snrs,\n","                                                                  seed=48\n","                                                                 )\n","\n","        # store statistic of whole dataset\n","        self.num_data = self.X_data.shape[0]\n","        self.num_lbl = len(self.target_modulations)\n","        self.num_snr = self.target_snrs.shape[0]\n","\n","\n","\n","    def __len__(self):\n","        return self.X_data.shape[0]\n","\n","    def __getitem__(self, idx):\n","        x,y,z = self.X_data[idx], self.Y_data[idx], self.Z_data[idx]\n","        x,y,z = torch.Tensor(x).transpose(0, 1) , y , z\n","        return x,y,z"]},{"cell_type":"code","execution_count":null,"id":"c620a70c","metadata":{"id":"c620a70c","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["ds = RadioML18Dataset(mode='test')\n","#x_test = ds.X_data\n","#y_test=ds.Y_data\n","data_len = ds.num_data\n","n_labels=ds.num_lbl\n","n_snrs = ds.num_snr\n","frame_size=ds.X.shape[1]\n","num_classes=ds.num_lbl\n","\n","Z=ds.Z\n","#frame_size=ds.X.shape[1]\n","snrs = ds.target_snrs"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ipqCYN44Ca9S","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"id":"ipqCYN44Ca9S","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"17118c16","metadata":{"id":"17118c16","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["import time\n","st = time.time()\n","train_dl = DataLoader(dataset=RadioML18Dataset(mode='train'),batch_size=64, shuffle=True, drop_last=True)\n","valid_dl = DataLoader(dataset=RadioML18Dataset(mode='valid'),batch_size=128, shuffle=False, drop_last=False)\n","test_dl = DataLoader(dataset=RadioML18Dataset(mode='test'),batch_size=128, shuffle=False, drop_last=False)\n","et = time.time()\n","elapsed_time = et - st\n","print('Execution time:', elapsed_time, 'seconds')"]},{"cell_type":"code","execution_count":null,"id":"209ac2ad","metadata":{"id":"209ac2ad","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["x_train=train_dl.dataset.X_data\n","# 获取训练集标签\n","y_train = train_dl.dataset.Y_data\n","\n","# 获取测试集输入数据和标签\n","x_test = test_dl.dataset.X_data\n","y_test = test_dl.dataset.Y_data\n","\n","x_valid = valid_dl.dataset.X_data\n","y_valid = valid_dl.dataset.Y_data\n","in_shp = list(x_train.shape[1:])\n","#x_valid = np.transpose(x_valid, (0, 2, 1))\n","print('x_train.shape',x_train.shape)\n","print('x_test.shape',x_test.shape)\n","print(\"y_test.shape: {}\".format(y_test.shape))\n","print('x_valid.shape',x_valid.shape)\n","print(\"input shape: {}\".format(in_shp))"]},{"cell_type":"code","execution_count":null,"id":"78fac6c5","metadata":{"id":"78fac6c5","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["def label_preprocess(y_train, y_test, num_classes):\n","\n","    num_classes = num_classes\n","    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","    return (y_train, y_test)\n","\n","(y_train, y_test), (y_train, y_valid) = label_preprocess(y_train, y_test, num_classes), label_preprocess(y_train, y_valid, num_classes)\n","print(y_train.shape)\n","print(y_test.shape)\n","print(y_valid.shape)"]},{"cell_type":"code","execution_count":null,"id":"4dbeb119","metadata":{"id":"4dbeb119","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["\n","dr = 0.5 # dropout rate\n","model = tf.keras.Sequential()\n","model.add(Conv2D(64, (1, 3), padding=\"same\", name=\"conv1\", kernel_initializer='glorot_uniform', input_shape = (1,1024,2)))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n","# Layer 2\n","model.add(Conv2D(64, (1, 3), padding=\"same\", name=\"conv2\", kernel_initializer='glorot_uniform'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n","# Layer 3\n","model.add(Conv2D(64, (1, 3), padding=\"same\", name=\"conv3\", kernel_initializer='glorot_uniform'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n","# Layer 4\n","model.add(Conv2D(64, (1, 3), padding=\"same\", name=\"conv4\", kernel_initializer='glorot_uniform'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n","# Layer 5\n","model.add(Conv2D(64, (1, 3), padding=\"same\", name=\"conv5\", kernel_initializer='glorot_uniform'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 2)))\n","# Layer 6\n","model.add(Conv2D(64, (1, 3), padding=\"same\", name=\"conv6\", kernel_initializer='glorot_uniform'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(AveragePooling2D(pool_size=(1, 16)))\n","# 压平进入全连接层\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu', kernel_initializer='he_normal', name=\"dense1\"))\n","model.add(Dropout(dr))\n","model.add(Dense(n_labels, kernel_initializer='he_normal', name=\"dense2\"))\n","model.add(Activation('softmax'))\n","model.add(Reshape([n_labels]))\n","\n","model.compile(Adam(learning_rate=0.001),loss='categorical_crossentropy',  metrics=['accuracy'])\n","model.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8e24822a","metadata":{"id":"8e24822a","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["nb_epoch = 10   # 训练初始设置为200轮，如果模型拟合完毕会提前结束\n","batch_size = 64  # 内存不够可以改小\n","X_train = np.reshape(x_train, (-1, 1,1024, 2))\n","\n","\n","X_test = np.reshape(x_test, (-1, 1,1024,2))\n","\n","X_valid = np.reshape(x_valid, (-1, 1,1024,2))\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","\n","filepath = '2018a_CCCC.wts.h5'\n","filepath = os.path.join(save_dir, filepath)\n","\n","history = model.fit(X_train,\n","                    y_train,\n","                    batch_size=batch_size,\n","                    epochs=nb_epoch,\n","                  verbose=2,\n","                    validation_data=(X_valid, y_valid),\n","                    callbacks = [\n","                        tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'),\n","                        #学习率系数0.5\n","                        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=4, verbose=1),\n","                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n","\n","    ])\n","model.load_weights(filepath)\n","_, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"]},{"cell_type":"code","execution_count":null,"id":"2cf2849b","metadata":{"id":"2cf2849b","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["x_test1=X_test\n","\n","for snr in snrs:\n","        # 获取当前SNR的测试样本和标签\n","        snr_indices = np.where(ds.Z_data == snr)[0]\n","        x_test_snr = x_test1[snr_indices]\n","        y_test_snr = y_test[snr_indices]\n","\n","        # 获取模型的预测\n","        y_pred_snr = model.predict(x_test_snr)\n","        y_pred_classes_snr = np.argmax(y_pred_snr, axis=1)\n","        y_true_classes_snr = np.argmax(y_test_snr, axis=1)\n","\n","        # 计算混淆矩阵\n","        conf_mat_snr = confusion_matrix(y_true_classes_snr, y_pred_classes_snr)\n","        # 获取调制方式的实际顺序\n","        actual_modulation_order = ds.target_modulations\n","\n","        # 绘制混淆矩阵热图\n","        # 绘制混淆矩阵热图\n","        plt.figure(figsize=(10, 8))\n","        sns.heatmap(conf_mat_snr, annot=True, fmt='d', cmap='Blues', xticklabels=actual_modulation_order, yticklabels=actual_modulation_order)\n","        plt.xlabel('Predictive labeling')\n","        plt.ylabel('truthful labeling')\n","        plt.title(f'confusion matrix (SNR={snr})')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"10d13b20","metadata":{"id":"10d13b20","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["\n","dr=0.5\n","batch_size = 512\n","epochs =200\n","input_x = Input(shape=(1024,2))\n","def residual_stack(x):\n","    def residual_unit(y, _strides=1):\n","        shortcut_unit = y\n","        # 1x1 conv linear\n","        y = Conv1D(64, kernel_size=10, data_format='channels_last', strides=_strides, padding='same',\n","                          activation='relu')(y)\n","        y = BatchNormalization()(y)\n","        y = Conv1D(64, kernel_size=10, data_format='channels_last', strides=_strides, padding='same',\n","                          activation='linear')(y)\n","        y = BatchNormalization()(y)\n","        # add batch normalization\n","        y = tf.keras.layers.add([shortcut_unit, y])\n","        return y\n","\n","    x = Conv1D(64, data_format='channels_last', kernel_size=1, padding='same', activation='linear')(x)\n","    x = BatchNormalization()(x)\n","    x = residual_unit(x)\n","    x = residual_unit(x)\n","    # maxpool for down sampling\n","    x = MaxPooling1D(data_format='channels_last')(x)\n","    return x\n","\n","x = residual_stack(input_x)\n","x = residual_stack(x)\n","x = residual_stack(x)\n","\n","x = Flatten()(x)\n","print(x.shape)\n","layer_dense1 = Dense(128, activation='relu', name=\"dense1\")(x)\n","layer_dropout = Dropout(dr)(layer_dense1)\n","layer_dense1 = Dense(128, activation='relu', name=\"dense2\")(layer_dropout)\n","layer_dropout = Dropout(dr)(layer_dense1)\n","layer_dense2 = Dense(num_classes,  name=\"dense3\")(layer_dropout)\n","layer_softmax = Activation('softmax')(layer_dense2)\n","output = Reshape([num_classes])(layer_softmax)\n","model1 = Model(inputs=input_x, outputs=output)\n","model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n","model1.summary()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ab901892","metadata":{"id":"ab901892","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["def residual_stack(X, Filters, Seq, max_pool):\n","    # 1*1 Conv Linear\n","    X = Conv2D(Filters, (1, 1), padding='same', name=Seq+\"_conv1\", kernel_initializer='glorot_uniform', data_format=\"channels_first\")(X)\n","    # Residual Unit 1\n","    X_shortcut = X\n","    X = Conv2D(Filters, (3, 2), padding='same', activation=\"relu\", name=Seq+\"_conv2\", kernel_initializer='glorot_uniform', data_format=\"channels_first\")(X)\n","    X = Conv2D(Filters, (3, 2), padding='same', name=Seq+\"_conv3\", kernel_initializer='glorot_uniform', data_format=\"channels_first\")(X)\n","    X = layers.add([X, X_shortcut])\n","    X = Activation(\"relu\")(X)\n","    # Residual Unit 2\n","    X_shortcut = X\n","    X = Conv2D(Filters, (3, 2), padding='same', activation=\"relu\", name=Seq+\"_conv4\", kernel_initializer='glorot_uniform', data_format=\"channels_first\")(X)\n","    X = Conv2D(Filters, (3, 2), padding='same', name=Seq+\"_conv5\", kernel_initializer='glorot_uniform', data_format=\"channels_first\")(X)\n","    X = layers.add([X, X_shortcut])\n","    X = Activation(\"relu\")(X)\n","    # MaxPooling\n","    if max_pool:\n","        X = MaxPooling2D(pool_size=(2, 1), strides=(2, 1), padding='valid', data_format=\"channels_last\")(X)\n","    return X\n","in_shp = x_train.shape[1:]   #每个样本的维度\n","# input layer\n","X_input = Input(in_shp)\n","X = Reshape([1, 1024, 2], input_shape=in_shp)(X_input)\n","# Residual Stack 1\n","X = residual_stack(X, 32, \"ReStk1\", False)  # shape:(1,512,32)\n","X = MaxPooling2D(pool_size=(2, 2), strides=(2, 1), padding='valid', data_format=\"channels_first\")(X)\n","# Residual Stack 2\n","X = residual_stack(X, 32, \"ReStk2\", True)  # shape:(1,256,32)\n","# Residual Stack 3\n","X = residual_stack(X, 32, \"ReStk3\", True)  # shape:(1,128,32)\n","# Residual Stack 4\n","X = residual_stack(X, 32, \"ReStk4\", True)  # shape:(1,64,32)\n","# Residual Stack 5\n","X = residual_stack(X, 32, \"ReStk5\", True)  # shape:(1,32,32)\n","# Residual Stack 6\n","X = residual_stack(X, 32, \"ReStk6\", True)  # shape:(1,16,32)\n","# Fully Connected 1\n","X = Flatten()(X)\n","X = Dense(128, activation='selu', kernel_initializer='he_normal', name=\"dense1\")(X)\n","X = AlphaDropout(0.3)(X)\n","X = Dense(128, activation='selu', kernel_initializer='he_normal', name=\"dense2\")(X)\n","X = AlphaDropout(0.3)(X)\n","X = Dense(n_labels, kernel_initializer='he_normal', name=\"dense3\")(X)\n","\n","# Softmax\n","X = Activation('softmax')(X)\n","# Create Model\n","model1 = Model(inputs=X_input, outputs=X)\n","model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n","model1.summary()"]},{"cell_type":"code","execution_count":null,"id":"3b42fe87","metadata":{"id":"3b42fe87","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["nb_epoch = 10   # number of epochs to train on\n","batch_size = 128\n","print(x_test.shape)\n","print(X_test.shape)\n","#X_test = np.reshape(x_test, (-1, 1,1024,2))\n","\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","\n","filepath1 = '2018a_123C.wts.h5'\n","filepath1 = os.path.join(save_dir, filepath1)\n","\n","history = model1.fit(x_train,\n","                    y_train,\n","                    batch_size=batch_size,\n","                    epochs=nb_epoch,\n","                    verbose=2,\n","                    validation_data=(x_valid, y_valid),\n","                    callbacks = [\n","                        tf.keras.callbacks.ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'),\n","                        #学习率系数0.5\n","                        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=4, verbose=1),\n","                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n","\n","    ])\n","model1.load_weights(filepath1)\n","_, accuracy = model1.evaluate(x_test, y_test)\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"]},{"cell_type":"code","execution_count":null,"id":"d097f7aa","metadata":{"id":"d097f7aa","executionInfo":{"status":"aborted","timestamp":1718194841433,"user_tz":-480,"elapsed":6,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["x_test2=x_test\n","print(x_test.shape)"]},{"cell_type":"code","execution_count":null,"id":"6f8d9bd5","metadata":{"id":"6f8d9bd5","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["#x_test = np.reshape(x_test, (-1, 1,1024,2))\n","for snr in snrs:\n","        # 获取当前SNR的测试样本和标签\n","        snr_indices = np.where(ds.Z_data == snr)[0]\n","        x_test_snr = x_test[snr_indices]\n","        y_test_snr = y_test[snr_indices]\n","\n","        # 获取模型的预测\n","        y_pred_snr = model1.predict(x_test_snr)\n","        y_pred_classes_snr = np.argmax(y_pred_snr, axis=1)\n","        y_true_classes_snr = np.argmax(y_test_snr, axis=1)\n","\n","        # 计算混淆矩阵\n","        conf_mat_snr = confusion_matrix(y_true_classes_snr, y_pred_classes_snr)\n","        # 获取调制方式的实际顺序\n","        actual_modulation_order = ds.target_modulations\n","\n","        # 绘制混淆矩阵热图\n","        # 绘制混淆矩阵热图\n","        plt.figure(figsize=(10, 8))\n","        sns.heatmap(conf_mat_snr, annot=True, fmt='d', cmap='Blues', xticklabels=actual_modulation_order, yticklabels=actual_modulation_order)\n","        plt.xlabel('Predictive labeling')\n","        plt.ylabel('truthful labeling')\n","        plt.title(f'confusion matrix (SNR={snr})')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"id":"582c0d43","metadata":{"id":"582c0d43","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["learning_rate = 0.01\n","weight_decay = 0.0001\n","batch_size = 256\n","num_epochs = 100\n","image_size = 1024  # resize重置输入大小\n","patch_size = 16 # 从输入图片（信号看作图片）中将被提取的块大小\n","input_shape =(2,1024,1)\n","# 分成 num_patches 个块\n","num_patches = (image_size // patch_size)\n","projection_dim = 64\n","num_heads = 3\n","transformer_units = [\n","    projection_dim * 2,\n","    projection_dim,\n","]  # Size of the transformer layers\n","transformer_layers = 5\n","mlp_head_units = [2048, 1024]\n","\n","# 数据标准化的均值和标准差计\n","\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.Normalization(),\n","        layers.experimental.preprocessing.Resizing(2, image_size),\n","\n","        layers.experimental.preprocessing.RandomZoom(\n","        height_factor=0.2, width_factor=0.2\n","        ),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","\n","data_augmentation.layers[0].adapt(x_train)"]},{"cell_type":"code","execution_count":null,"id":"d1dbbaaa","metadata":{"id":"d1dbbaaa","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x\n","\n","\n","\n","class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, 2, self.patch_size, 1],\n","            strides=[1, 2, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"patch_size\": self.patch_size,\n","        })\n","\n","        return config\n","def label_preprocess(y_train, y_test, num_classes):\n","\n","    num_classes = num_classes\n","    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","    return (y_train, y_test)\n","\n","print(y_train.shape)\n","print(y_test.shape)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(15, 15))\n","image = x_train[np.random.choice(range(x_train.shape[0]))]\n","plt.imshow(image.astype(\"uint8\"))\n","plt.axis(\"off\")\n","x_train1=x_train.reshape(-1,2,1024,1)\n","x_test1=x_test.reshape(-1,2,1024,1)\n","image = x_train1[np.random.choice(range(x_train.shape[0]))]\n","resized_image = tf.image.resize(\n","    tf.convert_to_tensor([image]), size=(2,image_size)\n",")\n","x_valid = np.vstack([batch[0].numpy() for batch in valid_dl])\n","#y_valid = np.concatenate([batch[1].numpy() for batch in valid_dl])\n","x_train = np.transpose(x_train, (0, 2, 1))\n","x_test = np.transpose(x_test, (0, 2, 1))\n","patches = Patches(patch_size)(resized_image)\n","\n","print(x_train.shape)\n","print(x_test.shape)\n","print(x_valid.shape)\n","n = int(patches.shape[1])\n","print(n)"]},{"cell_type":"code","execution_count":null,"id":"95701b13","metadata":{"id":"95701b13","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["from keras.layers import Activation\n","from keras.layers import Reshape\n","\n","\n","class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection_dim = projection_dim\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"num_patches\": self.num_patches,\n","            \"projection_dim\": self.projection_dim,\n","        })\n","        return config\n","\n","\n","def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    #augmented = data_augmentation(inputs)\n","    # 创建 patches.\n","    patches = Patches(patch_size)(inputs)\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # 创建Transformer层.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # 创建多头注意力机制层 multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","\n","    logits = layers.Dense(num_classes)(features)\n","\n","    layer_softmax = Activation('softmax')(logits)\n","    output = Reshape([num_classes])(layer_softmax)\n","\n","    # 创建模型.\n","    model = keras.Model(inputs=inputs, outputs=output)\n","    model.summary()\n","\n","    model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n","\n","    keras.utils.plot_model(model, to_file='graph_transformer.png', show_shapes=True)\n","    return model\n","\n","\n","def run_experiment(model, train_data_gen, valid_data_gen, save_path, initial_epochs, fine_tune_epochs):\n","    # 第一阶段训练（初始100轮）\n","    history = model.fit(\n","        train_data_gen,\n","        steps_per_epoch=len(x_train) // batch_size,\n","        epochs=initial_epochs,\n","        validation_data=valid_data_gen,\n","        validation_steps=len(x_valid) // batch_size,\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","            tf.keras.callbacks.CSVLogger('training.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,\n","    )\n","\n","    # 保存第一阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第一阶段训练的损失和准确性\n","    print(\"Phase 1 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history.history['loss'][-1], history.history['accuracy'][-1] * 100))\n","\n","    # 重新编译模型，使用 SGD 优化器和对应的学习率\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'])\n","\n","    # 第二阶段训练（再跑100轮）\n","    history_fine_tune = model.fit(\n","        train_data_gen,\n","        steps_per_epoch=len(x_train) // batch_size,\n","        epochs=fine_tune_epochs,\n","        validation_data=valid_data_gen,\n","        validation_steps=len(x_valid) // batch_size,\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs + fine_tune_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","            tf.keras.callbacks.CSVLogger('training_fine_tune.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,\n","    )\n","\n","    # 保存第二阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs + fine_tune_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第二阶段训练的损失和准确性\n","    print(\"Phase 2 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history_fine_tune.history['loss'][-1], history_fine_tune.history['accuracy'][-1] * 100))\n","\n","    for snr in snrs:\n","        # 获取当前SNR的测试样本和标签\n","        snr_indices = np.where(ds.Z_data == snr)[0]\n","        x_test_snr = x_test[snr_indices]\n","        y_test_snr = y_test[snr_indices]\n","\n","        # 获取模型的预测\n","        y_pred_snr = model.predict(x_test_snr)\n","        y_pred_classes_snr = np.argmax(y_pred_snr, axis=1)\n","        y_true_classes_snr = np.argmax(y_test_snr, axis=1)\n","\n","        # 计算混淆矩阵\n","        conf_mat_snr = confusion_matrix(y_true_classes_snr, y_pred_classes_snr)\n","        # 获取调制方式的实际顺序\n","        actual_modulation_order = ds.target_modulations\n","\n","        # 绘制混淆矩阵热图\n","        plt.figure(figsize=(10, 8))\n","        sns.heatmap(conf_mat_snr, annot=True, fmt='d', cmap='Blues', xticklabels=actual_modulation_order, yticklabels=actual_modulation_order)\n","        plt.xlabel('Predictive labeling')\n","        plt.ylabel('truthful labeling')\n","        plt.title(f'confusion matrix (SNR={snr})')\n","        plt.show()\n","\n","    return model, history, history_fine_tune"]},{"cell_type":"code","execution_count":null,"id":"df0ba90e","metadata":{"id":"df0ba90e","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["def data_generator(x, y, batch_size):\n","    num_samples = x.shape[0]\n","    indices = np.arange(num_samples)\n","    np.random.shuffle(indices)\n","\n","    while True:\n","        for start in range(0, num_samples, batch_size):\n","            end = min(start + batch_size, num_samples)\n","            batch_indices = indices[start:end]\n","            yield x[batch_indices], y[batch_indices]\n","\n","\n","\n","\n","batch_size = 512\n","train_data_gen = data_generator(x_train, y_train, batch_size)\n","valid_data_gen = data_generator(x_valid, y_valid, batch_size)\n","test_data_gen = data_generator(x_test, y_test, batch_size)\n","\n","# 调用 run_experiment 函数\n","vit_classifier = create_vit_classifier()"]},{"cell_type":"code","execution_count":null,"id":"69aa968e","metadata":{"id":"69aa968e","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["save_path = 'transformer_multigpu_epoch_{epoch:02d}.h5'  # 或者使用你想要的保存路径\n","initial_epochs = 8\n","fine_tune_epochs = 2\n","\n","\n","\n","model2, history2, history_fine_tune = run_experiment(vit_classifier, train_data_gen, valid_data_gen, save_path, initial_epochs, fine_tune_epochs)"]},{"cell_type":"code","execution_count":null,"id":"ccb60c4b","metadata":{"id":"ccb60c4b","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["print(\"Shape of x_test:\", x_test.shape)\n","print(\"Expected input shape of the model:\", model2.input_shape)\n"]},{"cell_type":"code","execution_count":null,"id":"c9d2507c","metadata":{"id":"c9d2507c","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["def plot_confusion_matrix(cm, title='Confusion matrix',normalize=False,cmap=plt.cm.Oranges, labels=[]):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","    plt.figure()\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(labels))\n","    plt.xticks(tick_marks, labels, rotation=45)\n","    plt.yticks(tick_marks, labels)\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","from matplotlib import pyplot\n","import matplotlib.pyplot as plt\n","import matplotlib\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n","\n","test_y_hat = model2.predict(x_test, batch_size=batch_size)\n","%matplotlib inline\n","#Y_test = meta_y_test\n","plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n","classes=ds.target_modulations\n","pre_labels = []\n","for x in test_y_hat:\n","    tmp = np.argmax(x, 0)\n","    pre_labels.append(tmp)\n","true_labels = []\n","for x in y_test:\n","    tmp = np.argmax(x, 0)\n","    true_labels.append(tmp)\n","\n","kappa = cohen_kappa_score(pre_labels, true_labels)\n","oa = accuracy_score(true_labels, pre_labels)\n","\n","kappa_oa = {}\n","print('oa_all:', oa)\n","print('kappa_all:', kappa)\n","kappa_oa['oa_all'] = oa\n","kappa_oa['kappa_all'] = kappa\n","\n","cnf_matrix = confusion_matrix(true_labels, pre_labels)\n","\n","plot_confusion_matrix(cnf_matrix, labels=classes,normalize=True,\n","                             title='Transformer Confusion Matrix')\n","\n","plot_confusion_matrix(cnf_matrix, labels=classes,normalize=False,\n","                             title='Transformer without normalization')"]},{"cell_type":"code","execution_count":null,"id":"f4dc0aef","metadata":{"id":"f4dc0aef","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["plt.figure()\n","plt.title('Training performance')\n","plt.plot(history.epoch, history.history['loss'], label='train loss+error')\n","plt.plot(history.epoch, history.history['val_loss'], label='val_error')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"id":"cc39bd41","metadata":{"id":"cc39bd41","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.ticker as mticker\n","\n","def plot_accuracy_by_snr(model, x_test, y_test, target_snrs, target_modulations, model_label):\n","    accuracies = []\n","\n","    for snr in target_snrs:\n","        # 获取当前SNR的测试样本和标签\n","        snr_indices = np.where(ds.Z_data == snr)[0]\n","        x_test_snr = x_test[snr_indices]\n","        y_test_snr = y_test[snr_indices]\n","\n","        # 获取模型的预测\n","        _, accuracy = model.evaluate(x_test_snr, y_test_snr, verbose=0)\n","        accuracies.append(accuracy * 100)  # 将准确率转换为百分比\n","\n","    # 绘制准确率图像\n","    plt.plot(target_snrs, accuracies, marker='o', label=f'{model_label}')\n","x_test3=x_test\n","# 使用适当的标签调用函数\n","plot_accuracy_by_snr(model, X_test, y_test, snrs, ds.target_modulations, model_label=\"CNN\")\n","plot_accuracy_by_snr(model1, x_test2, y_test, snrs, ds.target_modulations, model_label=\"RESNET\")\n","plot_accuracy_by_snr(model2, x_test3, y_test, snrs, ds.target_modulations, model_label=\"VIT\")\n","plt.xlabel('SNR')\n","plt.ylabel('accuracy (%)')  # 在标签中添加百分号\n","plt.xticks(snrs)  # 设置x轴刻度为目标SNR值\n","plt.gca().yaxis.set_major_formatter(mticker.PercentFormatter())  # 设置y轴为百分比格式\n","plt.grid(True)\n","plt.legend()\n","plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"bf3bec7e","metadata":{"id":"bf3bec7e","executionInfo":{"status":"aborted","timestamp":1718194841434,"user_tz":-480,"elapsed":7,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"tensorflow","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}