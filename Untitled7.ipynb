{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"63EJF8BSqM9r"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19138,"status":"ok","timestamp":1710337244339,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"3c5abc97","outputId":"ed250549-06cd-4a28-9cd0-1776472fad06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras-tqdm\n","  Downloading keras_tqdm-2.0.1-py2.py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.10/dist-packages (from keras-tqdm) (2.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-tqdm) (4.66.2)\n","Installing collected packages: keras-tqdm\n","Successfully installed keras-tqdm-2.0.1\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]}],"source":["!pip install keras-tqdm\n","!pip install torchinfo\n","\n","import numpy as np\n","from numpy import linalg as la\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.models as models\n","from keras_tqdm import TQDMNotebookCallback\n","import pickle, random\n","import os,sys\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from sklearn.preprocessing import label_binarize\n","from tensorflow.keras.callbacks import TensorBoard\n","import h5py\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","from matplotlib import pyplot\n","from matplotlib.font_manager import FontProperties\n","from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n","import matplotlib\n","\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import h5py\n","import json\n","from matplotlib import pyplot as plt\n","import torch\n","from torch import nn\n","from torchinfo import summary\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import trange, tqdm\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","import pickle, random\n","import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from sklearn.preprocessing import label_binarize\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddff291c"},"outputs":[],"source":["n_channels=2\n","batch_size=32\n","# Number of frames per snr/modulation combination for train,valid and test data\n","nf_train = 1024\n","nf_valid = 512\n","nf_test = 512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce4826cd"},"outputs":[],"source":["def dataset_split(data,\n","                   modulations_classes,\n","                   modulations,snrs,\n","                   target_modulations,\n","                   mode,\n","                   target_snrs,train_proportion,\n","                   valid_proportion,\n","                   test_proportion,\n","                   seed=48):\n","    np.random.seed(seed)\n","    train_split_index = int(train_proportion*1396)\n","    valid_split_index = int((valid_proportion+train_proportion)*1396)\n","    test_split_index = int((test_proportion+valid_proportion+train_proportion)*1396)\n","    X_output=[]\n","    Y_output=[]\n","    Z_output=[]\n","\n","    target_modulation_indices = [modulations_classes.index(modu) for modu in target_modulations]\n","\n","    for modu in  target_modulation_indices:\n","        for snr in target_snrs:\n","            snr_modu_indices = np.where((modulations==modu) & (snrs==snr))[0]\n","\n","            np.random.shuffle(snr_modu_indices)\n","            train, valid, test, remaining = np.split(snr_modu_indices, [train_split_index,valid_split_index,test_split_index])\n","            if mode=='train':\n","                X_output.append(data[np.sort(train)])\n","                Y_output.append(modulations[np.sort(train)])\n","                Z_output.append(snrs[np.sort(train)])\n","            elif mode=='valid':\n","                X_output.append(data[np.sort(valid)])\n","                Y_output.append(modulations[np.sort(valid)])\n","                Z_output.append(snrs[np.sort(valid)])\n","            elif mode =='test':\n","                X_output.append(data[np.sort(test)])\n","                Y_output.append(modulations[np.sort(test)])\n","                Z_output.append(snrs[np.sort(test)])\n","            else:\n","                raise ValueError(f'unknown mode: {mode}. Valid modes are train, valid and test')\n","    X_array = np.vstack(X_output)\n","    Y_array = np.concatenate(Y_output)\n","    Z_array = np.concatenate(Z_output)\n","    for index,value in enumerate(np.unique(np.copy(Y_array))):\n","        Y_array[Y_array==value]=index\n","    return X_array, Y_array, Z_array\n","\n","\n","\n","class RadioML18Dataset(Dataset):\n","    def __init__(self, mode: str,seed=48,):\n","        super(RadioML18Dataset, self).__init__()\n","\n","        # load data\n","        #hdf5_file = h5py.File(\"/content/drive/MyDrive/GOLD_XYZ_OSC.0001_1024.hdf5\",  'r')\n","        hdf5_file = h5py.File(\"/content/drive/MyDrive/GOLD_XYZ_OSC.0001_1024_mini.hdf5\",  'r')\n","        self.modulation_classes = json.load(open(\"/content/drive/MyDrive/classes-fixed.json\", 'r'))\n","        self.X = hdf5_file['X']\n","        self.Y = np.argmax(hdf5_file['Y'], axis=1)\n","        self.Z = hdf5_file['Z'][:, 0]\n","\n","        #train_proportion=(24*26*nf_train)/self.X.shape[0]\n","        #test_proportion=(24*26*nf_test)/self.X.shape[0]\n","#         target_modulations =['OOK','4ASK','8ASK','BPSK', 'QPSK','8PSK','16PSK','32PSK','16APSK', '32APSK','64APSK','128APSK',\n","   #    '16QAM', '32QAM','64QAM','128QAM','256QAM','AM-SSB-WC','AM-SSB-SC','AM-DSB-WC',\n","     #   'AM-DSB-SC','FM', 'GMSK','OQPSK']\n","        train_proportion=(24*26*nf_train)/self.X.shape[0]\n","        valid_proportion=(24*26*nf_valid)/self.X.shape[0]\n","        test_proportion=(24*26*nf_test)/self.X.shape[0]\n","        # Target modulation class and snr\n","        self.target_modulations = ['OOK','4ASK','8ASK','8PSK','16PSK','32PSK','16APSK', '32APSK','64APSK','128APSK',\n","       '16QAM', '32QAM','64QAM','128QAM','256QAM','AM-SSB-WC','AM-SSB-SC','AM-DSB-WC','AM-DSB-SC','FM', 'GMSK','OQPSK'\n","       ]\n","\n","\n","        self.target_snrs = np.unique(self.Z)\n","\n","\n","        self.X_data, self.Y_data, self.Z_data = dataset_split(\n","                                                                  data = self.X,\n","                                                                  modulations_classes = self.modulation_classes,\n","                                                                  modulations = self.Y,\n","                                                                  snrs = self.Z,\n","                                                                  mode = mode,\n","                                                                  train_proportion = train_proportion,\n","                                                                  valid_proportion = valid_proportion,\n","                                                                  test_proportion = test_proportion,\n","                                                                  target_modulations = self.target_modulations,\n","                                                                  target_snrs  = self.target_snrs,\n","                                                                  seed=48\n","                                                                 )\n","\n","        # store statistic of whole dataset\n","        self.num_data = self.X_data.shape[0]\n","        self.num_lbl = len(self.target_modulations)\n","        self.num_snr = self.target_snrs.shape[0]\n","\n","\n","\n","    def __len__(self):\n","        return self.X_data.shape[0]\n","\n","    def __getitem__(self, idx):\n","        x,y,z = self.X_data[idx], self.Y_data[idx], self.Z_data[idx]\n","        x,y,z = torch.Tensor(x).transpose(0, 1) , y , z\n","        return x,y,z"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25148,"status":"ok","timestamp":1710337269483,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"UUL3SmodVvM_","outputId":"298955cd-7b6d-41e8-a5c3-3d71e1a961a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62144f23"},"outputs":[],"source":["ds = RadioML18Dataset(mode='test')\n","#x_test = ds.X_data\n","#y_test=ds.Y_data\n","data_len = ds.num_data\n","n_labels=ds.num_lbl\n","n_snrs = ds.num_snr\n","frame_size=ds.X.shape[1]\n","num_classes=ds.num_lbl\n","\n","Z=ds.Z\n","#frame_size=ds.X.shape[1]\n","snrs = ds.target_snrs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lReUB0BKJDEJ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46104,"status":"ok","timestamp":1710337431666,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"821153f1","outputId":"1be34062-5cc3-4a95-8e22-f416fecff567"},"outputs":[{"output_type":"stream","name":"stdout","text":["Execution time: 46.536635875701904 seconds\n"]}],"source":["import time\n","st = time.time()\n","train_dl = DataLoader(dataset=RadioML18Dataset(mode='train'),batch_size=64, shuffle=True, drop_last=True)\n","valid_dl = DataLoader(dataset=RadioML18Dataset(mode='valid'),batch_size=64, shuffle=False, drop_last=False)\n","test_dl = DataLoader(dataset=RadioML18Dataset(mode='test'),batch_size=64, shuffle=False, drop_last=False)\n","et = time.time()\n","elapsed_time = et - st\n","print('Execution time:', elapsed_time, 'seconds')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710337431667,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"289d81e3","outputId":"53996137-05b6-4341-e614-0fc3bab2d8d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train.shape (199320, 1024, 2)\n","x_test.shape (99660, 1024, 2)\n","y_test.shape: (99660,)\n","x_valid.shape (99990, 1024, 2)\n","input shape: [1024, 2]\n"]}],"source":["x_train=train_dl.dataset.X_data\n","# 获取训练集标签\n","y_train = train_dl.dataset.Y_data\n","\n","# 获取测试集输入数据和标签\n","x_test = test_dl.dataset.X_data\n","y_test = test_dl.dataset.Y_data\n","\n","x_valid = valid_dl.dataset.X_data\n","y_valid = valid_dl.dataset.Y_data\n","in_shp = list(x_train.shape[1:])\n","#x_valid = np.transpose(x_valid, (0, 2, 1))\n","print('x_train.shape',x_train.shape)\n","print('x_test.shape',x_test.shape)\n","print(\"y_test.shape: {}\".format(y_test.shape))\n","print('x_valid.shape',x_valid.shape)\n","print(\"input shape: {}\".format(in_shp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710337431667,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"02648f21","outputId":"f3931db3-0f12-4246-8797-0c885478a7ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["(199320, 22)\n","(99660, 22)\n","(99990, 22)\n"]}],"source":["def label_preprocess(y_train, y_test, num_classes):\n","\n","    num_classes = num_classes\n","    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","    return (y_train, y_test)\n","\n","(y_train, y_test), (y_train, y_valid) = label_preprocess(y_train, y_test, num_classes), label_preprocess(y_train, y_valid, num_classes)\n","print(y_train.shape)\n","print(y_test.shape)\n","print(y_valid.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbgOW212Gq1W"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ijfxT3b7EJM3"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19d724f8"},"outputs":[],"source":["#learning_rate = 0.1\n","weight_decay = 0.0001\n","batch_size = 800\n","num_epochs = 100\n","image_size = 1024  # resize重置输入大小\n","patch_size = 8 # 从输入图片（信号看作图片）中将被提取的块大小\n","input_shape =(2,1024,1)\n","# 分成 num_patches 个块\n","num_patches = (image_size // patch_size)\n","projection_dim = 64\n","num_heads = 13\n","transformer_units = [\n","    projection_dim * 2,\n","    projection_dim,\n","]  # Size of the transformer layers\n","transformer_layers = 9\n","mlp_head_units = [2048, 1024]\n","\n","# 数据标准化的均值和标准差计\n","\n","data_augmentation = keras.Sequential(\n","    [\n","        layers.experimental.preprocessing.Normalization(),\n","        layers.experimental.preprocessing.Resizing(2, image_size),\n","\n","        layers.experimental.preprocessing.RandomZoom(\n","        height_factor=0.2, width_factor=0.2\n","        ),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","\n","data_augmentation.layers[0].adapt(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1885,"status":"ok","timestamp":1710337445796,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"384d3137","outputId":"0fa606a1-6ae6-44a7-a58c-0b5ee1d973c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["(199320, 22)\n","(99660, 22)\n","(199320, 2, 1024)\n","(99660, 2, 1024)\n","(99990, 2, 1024)\n","64\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x1500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x\n","\n","\n","\n","class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, 2, self.patch_size, 1],\n","            strides=[1, 2, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"patch_size\": self.patch_size,\n","        })\n","\n","        return config\n","def label_preprocess(y_train, y_test, num_classes):\n","\n","    num_classes = num_classes\n","    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","    return (y_train, y_test)\n","\n","print(y_train.shape)\n","print(y_test.shape)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(15, 15))\n","image = x_train[np.random.choice(range(x_train.shape[0]))]\n","plt.imshow(image.astype(\"uint8\"))\n","plt.axis(\"off\")\n","x_train1=x_train.reshape(-1,2,1024,1)\n","x_test1=x_test.reshape(-1,2,1024,1)\n","image = x_train1[np.random.choice(range(x_train.shape[0]))]\n","resized_image = tf.image.resize(\n","    tf.convert_to_tensor([image]), size=(2,image_size)\n",")\n","x_valid = np.vstack([batch[0].numpy() for batch in valid_dl])\n","#y_valid = np.concatenate([batch[1].numpy() for batch in valid_dl])\n","x_train = np.transpose(x_train, (0, 2, 1))\n","x_test = np.transpose(x_test, (0, 2, 1))\n","patches = Patches(patch_size)(resized_image)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1769,"status":"ok","timestamp":1710337447561,"user":{"displayName":"xu yuewen","userId":"17936299490326054094"},"user_tz":-480},"id":"cc5f0208","outputId":"ed547b82-1798-4b96-8f6c-72635c20e256"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 2, 1024, 1)]         0         []                            \n","                                                                                                  \n"," patches_1 (Patches)         (None, None, 32)             0         ['input_1[0][0]']             \n","                                                                                                  \n"," patch_encoder (PatchEncode  (None, 64, 64)               6208      ['patches_1[0][0]']           \n"," r)                                                                                               \n","                                                                                                  \n"," layer_normalization (Layer  (None, 64, 64)               128       ['patch_encoder[0][0]']       \n"," Normalization)                                                                                   \n","                                                                                                  \n"," multi_head_attention (Mult  (None, 64, 64)               248704    ['layer_normalization[0][0]', \n"," iHeadAttention)                                                     'layer_normalization[0][0]'] \n","                                                                                                  \n"," add (Add)                   (None, 64, 64)               0         ['multi_head_attention[0][0]',\n","                                                                     'patch_encoder[0][0]']       \n","                                                                                                  \n"," layer_normalization_1 (Lay  (None, 64, 64)               128       ['add[0][0]']                 \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," dense_1 (Dense)             (None, 64, 128)              8320      ['layer_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout (Dropout)           (None, 64, 128)              0         ['dense_1[0][0]']             \n","                                                                                                  \n"," dense_2 (Dense)             (None, 64, 64)               8256      ['dropout[0][0]']             \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 64, 64)               0         ['dense_2[0][0]']             \n","                                                                                                  \n"," add_1 (Add)                 (None, 64, 64)               0         ['dropout_1[0][0]',           \n","                                                                     'add[0][0]']                 \n","                                                                                                  \n"," layer_normalization_2 (Lay  (None, 64, 64)               128       ['add_1[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," multi_head_attention_1 (Mu  (None, 64, 64)               248704    ['layer_normalization_2[0][0]'\n"," ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," add_2 (Add)                 (None, 64, 64)               0         ['multi_head_attention_1[0][0]\n","                                                                    ',                            \n","                                                                     'add_1[0][0]']               \n","                                                                                                  \n"," layer_normalization_3 (Lay  (None, 64, 64)               128       ['add_2[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," dense_3 (Dense)             (None, 64, 128)              8320      ['layer_normalization_3[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 64, 128)              0         ['dense_3[0][0]']             \n","                                                                                                  \n"," dense_4 (Dense)             (None, 64, 64)               8256      ['dropout_2[0][0]']           \n","                                                                                                  \n"," dropout_3 (Dropout)         (None, 64, 64)               0         ['dense_4[0][0]']             \n","                                                                                                  \n"," add_3 (Add)                 (None, 64, 64)               0         ['dropout_3[0][0]',           \n","                                                                     'add_2[0][0]']               \n","                                                                                                  \n"," layer_normalization_4 (Lay  (None, 64, 64)               128       ['add_3[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," multi_head_attention_2 (Mu  (None, 64, 64)               248704    ['layer_normalization_4[0][0]'\n"," ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," add_4 (Add)                 (None, 64, 64)               0         ['multi_head_attention_2[0][0]\n","                                                                    ',                            \n","                                                                     'add_3[0][0]']               \n","                                                                                                  \n"," layer_normalization_5 (Lay  (None, 64, 64)               128       ['add_4[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," dense_5 (Dense)             (None, 64, 128)              8320      ['layer_normalization_5[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_4 (Dropout)         (None, 64, 128)              0         ['dense_5[0][0]']             \n","                                                                                                  \n"," dense_6 (Dense)             (None, 64, 64)               8256      ['dropout_4[0][0]']           \n","                                                                                                  \n"," dropout_5 (Dropout)         (None, 64, 64)               0         ['dense_6[0][0]']             \n","                                                                                                  \n"," add_5 (Add)                 (None, 64, 64)               0         ['dropout_5[0][0]',           \n","                                                                     'add_4[0][0]']               \n","                                                                                                  \n"," layer_normalization_6 (Lay  (None, 64, 64)               128       ['add_5[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," multi_head_attention_3 (Mu  (None, 64, 64)               248704    ['layer_normalization_6[0][0]'\n"," ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," add_6 (Add)                 (None, 64, 64)               0         ['multi_head_attention_3[0][0]\n","                                                                    ',                            \n","                                                                     'add_5[0][0]']               \n","                                                                                                  \n"," layer_normalization_7 (Lay  (None, 64, 64)               128       ['add_6[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," dense_7 (Dense)             (None, 64, 128)              8320      ['layer_normalization_7[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_6 (Dropout)         (None, 64, 128)              0         ['dense_7[0][0]']             \n","                                                                                                  \n"," dense_8 (Dense)             (None, 64, 64)               8256      ['dropout_6[0][0]']           \n","                                                                                                  \n"," dropout_7 (Dropout)         (None, 64, 64)               0         ['dense_8[0][0]']             \n","                                                                                                  \n"," add_7 (Add)                 (None, 64, 64)               0         ['dropout_7[0][0]',           \n","                                                                     'add_6[0][0]']               \n","                                                                                                  \n"," layer_normalization_8 (Lay  (None, 64, 64)               128       ['add_7[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," multi_head_attention_4 (Mu  (None, 64, 64)               248704    ['layer_normalization_8[0][0]'\n"," ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," add_8 (Add)                 (None, 64, 64)               0         ['multi_head_attention_4[0][0]\n","                                                                    ',                            \n","                                                                     'add_7[0][0]']               \n","                                                                                                  \n"," layer_normalization_9 (Lay  (None, 64, 64)               128       ['add_8[0][0]']               \n"," erNormalization)                                                                                 \n","                                                                                                  \n"," dense_9 (Dense)             (None, 64, 128)              8320      ['layer_normalization_9[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_8 (Dropout)         (None, 64, 128)              0         ['dense_9[0][0]']             \n","                                                                                                  \n"," dense_10 (Dense)            (None, 64, 64)               8256      ['dropout_8[0][0]']           \n","                                                                                                  \n"," dropout_9 (Dropout)         (None, 64, 64)               0         ['dense_10[0][0]']            \n","                                                                                                  \n"," add_9 (Add)                 (None, 64, 64)               0         ['dropout_9[0][0]',           \n","                                                                     'add_8[0][0]']               \n","                                                                                                  \n"," layer_normalization_10 (La  (None, 64, 64)               128       ['add_9[0][0]']               \n"," yerNormalization)                                                                                \n","                                                                                                  \n"," flatten (Flatten)           (None, 4096)                 0         ['layer_normalization_10[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," dropout_10 (Dropout)        (None, 4096)                 0         ['flatten[0][0]']             \n","                                                                                                  \n"," dense_11 (Dense)            (None, 2048)                 8390656   ['dropout_10[0][0]']          \n","                                                                                                  \n"," dropout_11 (Dropout)        (None, 2048)                 0         ['dense_11[0][0]']            \n","                                                                                                  \n"," dense_12 (Dense)            (None, 1024)                 2098176   ['dropout_11[0][0]']          \n","                                                                                                  \n"," dropout_12 (Dropout)        (None, 1024)                 0         ['dense_12[0][0]']            \n","                                                                                                  \n"," dense_13 (Dense)            (None, 22)                   22550     ['dropout_12[0][0]']          \n","                                                                                                  \n"," activation (Activation)     (None, 22)                   0         ['dense_13[0][0]']            \n","                                                                                                  \n"," reshape (Reshape)           (None, 22)                   0         ['activation[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 11845398 (45.19 MB)\n","Trainable params: 11845398 (45.19 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["from keras.layers import Activation\n","from keras.layers import Reshape\n","\n","\n","class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection_dim = projection_dim\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"num_patches\": self.num_patches,\n","            \"projection_dim\": self.projection_dim,\n","        })\n","        return config\n","\n","\n","def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    #augmented = data_augmentation(inputs)\n","    # 创建 patches.\n","    patches = Patches(patch_size)(inputs)\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # 创建Transformer层.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # 创建多头注意力机制层 multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","\n","    logits = layers.Dense(num_classes)(features)\n","\n","    layer_softmax = Activation('softmax')(logits)\n","    output = Reshape([num_classes])(layer_softmax)\n","\n","    # 创建模型.\n","    model = keras.Model(inputs=inputs, outputs=output)\n","    model.summary()\n","    #model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n","    #model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n","    keras.utils.plot_model(model, to_file='graph_transformer.png', show_shapes=True)\n","    return model\n","\n","\n","def run_experiment(model, save_path, initial_epochs, fine_tune_epochs):\n","    # 第一阶段训练（初始100轮）\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=initial_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","        tf.keras.callbacks.CSVLogger('training.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,)\n","\n","    # 保存第一阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第一阶段训练的损失和准确性\n","    print(\"Phase 1 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history.history['loss'][-1], history.history['accuracy'][-1] * 100))\n","\n","    # 重新编译模型，使用 SGD 优化器和对应的学习率\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'])\n","\n","    # 第二阶段训练（再跑100轮）\n","    history_fine_tune = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=fine_tune_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs + fine_tune_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","            tf.keras.callbacks.CSVLogger('training_fine_tune.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,\n","    )\n","\n","    # 保存第二阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs + fine_tune_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第二阶段训练的损失和准确性\n","    print(\"Phase 2 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history_fine_tune.history['loss'][-1], history_fine_tune.history['accuracy'][-1] * 100))\n","\n","    return model, history, history_fine_tune\n","\n","vit_classifier1 = create_vit_classifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"859906f6","outputId":"81d5cfa8-058e-4788-f195-bbca5ee42f4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","779/779 [==============================] - 84s 86ms/step - loss: 1.7234 - accuracy: 0.3435 - val_loss: 1.2410 - val_accuracy: 0.4607\n","Epoch 2/100\n","779/779 [==============================] - 65s 84ms/step - loss: 1.2263 - accuracy: 0.4673 - val_loss: 1.1365 - val_accuracy: 0.4952\n","Epoch 3/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1663 - accuracy: 0.4894 - val_loss: 1.0751 - val_accuracy: 0.5169\n","Epoch 4/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1192 - accuracy: 0.5031 - val_loss: 1.0286 - val_accuracy: 0.5313\n","Epoch 5/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.0613 - accuracy: 0.5245 - val_loss: 1.0786 - val_accuracy: 0.5180\n","Epoch 6/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.0560 - accuracy: 0.5303 - val_loss: 1.2625 - val_accuracy: 0.4671\n","Epoch 7/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.2578 - accuracy: 0.4698 - val_loss: 1.8604 - val_accuracy: 0.3289\n","Epoch 8/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.3075 - accuracy: 0.4525 - val_loss: 1.4613 - val_accuracy: 0.4249\n","Epoch 9/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.3270 - accuracy: 0.4467 - val_loss: 1.2028 - val_accuracy: 0.4737\n","Epoch 10/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.2662 - accuracy: 0.4607 - val_loss: 1.2304 - val_accuracy: 0.4696\n","Epoch 11/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.2222 - accuracy: 0.4704 - val_loss: 1.1768 - val_accuracy: 0.4832\n","Epoch 12/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1922 - accuracy: 0.4804 - val_loss: 1.1289 - val_accuracy: 0.4979\n","Epoch 13/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1544 - accuracy: 0.4935 - val_loss: 1.1749 - val_accuracy: 0.4917\n","Epoch 14/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1773 - accuracy: 0.4872 - val_loss: 1.1265 - val_accuracy: 0.5025\n","Epoch 15/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1697 - accuracy: 0.4893 - val_loss: 1.1143 - val_accuracy: 0.5046\n","Epoch 16/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1902 - accuracy: 0.4823 - val_loss: 1.1626 - val_accuracy: 0.4900\n","Epoch 17/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1564 - accuracy: 0.4923 - val_loss: 1.1074 - val_accuracy: 0.5081\n","Epoch 18/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.1235 - accuracy: 0.5035 - val_loss: 1.0934 - val_accuracy: 0.5089\n","Epoch 19/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1670 - accuracy: 0.4910 - val_loss: 1.1588 - val_accuracy: 0.4905\n","Epoch 20/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1543 - accuracy: 0.4936 - val_loss: 1.0948 - val_accuracy: 0.5088\n","Epoch 21/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1356 - accuracy: 0.5018 - val_loss: 1.1071 - val_accuracy: 0.5076\n","Epoch 22/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1406 - accuracy: 0.5005 - val_loss: 1.1244 - val_accuracy: 0.5025\n","Epoch 23/100\n","779/779 [==============================] - 64s 83ms/step - loss: 1.1331 - accuracy: 0.5016 - val_loss: 1.0705 - val_accuracy: 0.5162\n","Epoch 24/100\n","779/779 [==============================] - 65s 83ms/step - loss: 1.0790 - accuracy: 0.5204 - val_loss: 1.0508 - val_accuracy: 0.5330\n","Epoch 25/100\n","779/779 [==============================] - 65s 84ms/step - loss: 1.0398 - accuracy: 0.5381 - val_loss: 0.9710 - val_accuracy: 0.5684\n","Epoch 26/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.9650 - accuracy: 0.5714 - val_loss: 0.9078 - val_accuracy: 0.5939\n","Epoch 27/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.8758 - accuracy: 0.6081 - val_loss: 0.7555 - val_accuracy: 0.6548\n","Epoch 28/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.7952 - accuracy: 0.6405 - val_loss: 0.7090 - val_accuracy: 0.6734\n","Epoch 29/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.7207 - accuracy: 0.6702 - val_loss: 0.6538 - val_accuracy: 0.6942\n","Epoch 30/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.6659 - accuracy: 0.6918 - val_loss: 0.5817 - val_accuracy: 0.7267\n","Epoch 31/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.6190 - accuracy: 0.7113 - val_loss: 0.5756 - val_accuracy: 0.7250\n","Epoch 32/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.5853 - accuracy: 0.7255 - val_loss: 0.5110 - val_accuracy: 0.7536\n","Epoch 33/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.5610 - accuracy: 0.7359 - val_loss: 0.5738 - val_accuracy: 0.7302\n","Epoch 34/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.5432 - accuracy: 0.7451 - val_loss: 0.5449 - val_accuracy: 0.7398\n","Epoch 35/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.5270 - accuracy: 0.7535 - val_loss: 0.4872 - val_accuracy: 0.7669\n","Epoch 36/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.5103 - accuracy: 0.7588 - val_loss: 0.4685 - val_accuracy: 0.7756\n","Epoch 37/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4982 - accuracy: 0.7657 - val_loss: 0.4831 - val_accuracy: 0.7719\n","Epoch 38/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4834 - accuracy: 0.7720 - val_loss: 0.4728 - val_accuracy: 0.7753\n","Epoch 39/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4744 - accuracy: 0.7754 - val_loss: 0.4528 - val_accuracy: 0.7871\n","Epoch 40/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4668 - accuracy: 0.7783 - val_loss: 0.4370 - val_accuracy: 0.7920\n","Epoch 41/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4584 - accuracy: 0.7831 - val_loss: 0.4271 - val_accuracy: 0.7945\n","Epoch 42/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4516 - accuracy: 0.7850 - val_loss: 0.4509 - val_accuracy: 0.7856\n","Epoch 43/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4414 - accuracy: 0.7915 - val_loss: 0.4255 - val_accuracy: 0.7980\n","Epoch 44/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4412 - accuracy: 0.7910 - val_loss: 0.4435 - val_accuracy: 0.7929\n","Epoch 45/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4289 - accuracy: 0.7970 - val_loss: 0.4133 - val_accuracy: 0.8039\n","Epoch 46/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4241 - accuracy: 0.7985 - val_loss: 0.4042 - val_accuracy: 0.8069\n","Epoch 47/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4189 - accuracy: 0.8007 - val_loss: 0.4218 - val_accuracy: 0.7968\n","Epoch 48/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4134 - accuracy: 0.8025 - val_loss: 0.4048 - val_accuracy: 0.8063\n","Epoch 49/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4069 - accuracy: 0.8054 - val_loss: 0.4011 - val_accuracy: 0.8108\n","Epoch 50/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.4153 - accuracy: 0.8041 - val_loss: 0.4063 - val_accuracy: 0.8058\n","Epoch 51/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.4013 - val_accuracy: 0.8070\n","Epoch 52/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3922 - accuracy: 0.8126 - val_loss: 0.3945 - val_accuracy: 0.8113\n","Epoch 53/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3920 - accuracy: 0.8125 - val_loss: 0.5532 - val_accuracy: 0.7531\n","Epoch 54/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3912 - accuracy: 0.8128 - val_loss: 0.3974 - val_accuracy: 0.8121\n","Epoch 55/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3838 - accuracy: 0.8163 - val_loss: 0.3800 - val_accuracy: 0.8191\n","Epoch 56/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3905 - accuracy: 0.8132 - val_loss: 0.3801 - val_accuracy: 0.8186\n","Epoch 57/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3772 - accuracy: 0.8185 - val_loss: 0.3673 - val_accuracy: 0.8225\n","Epoch 58/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3748 - accuracy: 0.8194 - val_loss: 0.3766 - val_accuracy: 0.8220\n","Epoch 59/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3720 - accuracy: 0.8205 - val_loss: 0.3731 - val_accuracy: 0.8185\n","Epoch 60/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3682 - accuracy: 0.8224 - val_loss: 0.3796 - val_accuracy: 0.8208\n","Epoch 61/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3678 - accuracy: 0.8224 - val_loss: 0.3721 - val_accuracy: 0.8203\n","Epoch 62/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.3643 - accuracy: 0.8233 - val_loss: 0.3617 - val_accuracy: 0.8250\n","Epoch 63/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3641 - accuracy: 0.8238 - val_loss: 0.3560 - val_accuracy: 0.8279\n","Epoch 64/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3619 - accuracy: 0.8241 - val_loss: 0.3735 - val_accuracy: 0.8204\n","Epoch 65/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3534 - accuracy: 0.8280 - val_loss: 0.3568 - val_accuracy: 0.8274\n","Epoch 66/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3579 - accuracy: 0.8263 - val_loss: 0.3591 - val_accuracy: 0.8266\n","Epoch 67/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3515 - accuracy: 0.8283 - val_loss: 0.3684 - val_accuracy: 0.8245\n","Epoch 68/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.3535 - accuracy: 0.8274 - val_loss: 0.3638 - val_accuracy: 0.8243\n","Epoch 69/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.3457 - accuracy: 0.8320 - val_loss: 0.3796 - val_accuracy: 0.8231\n","Epoch 70/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.3492 - accuracy: 0.8303 - val_loss: 0.3640 - val_accuracy: 0.8250\n","Epoch 71/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3437 - accuracy: 0.8324 - val_loss: 0.3666 - val_accuracy: 0.8243\n","Epoch 72/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3417 - accuracy: 0.8327 - val_loss: 0.3645 - val_accuracy: 0.8259\n","Epoch 73/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3357 - accuracy: 0.8356 - val_loss: 0.3645 - val_accuracy: 0.8263\n","Epoch 74/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3371 - accuracy: 0.8356 - val_loss: 0.3635 - val_accuracy: 0.8278\n","Epoch 75/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.3334 - accuracy: 0.8373 - val_loss: 0.3557 - val_accuracy: 0.8311\n","Epoch 76/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3333 - accuracy: 0.8378 - val_loss: 0.3638 - val_accuracy: 0.8274\n","Epoch 77/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.3316 - accuracy: 0.8381 - val_loss: 0.3734 - val_accuracy: 0.8252\n","Epoch 78/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3284 - accuracy: 0.8401 - val_loss: 0.3637 - val_accuracy: 0.8290\n","Epoch 79/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3251 - accuracy: 0.8406 - val_loss: 0.3649 - val_accuracy: 0.8287\n","Epoch 80/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.3267 - accuracy: 0.8418 - val_loss: 0.3457 - val_accuracy: 0.8408\n","Epoch 81/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.3233 - accuracy: 0.8470 - val_loss: 0.3315 - val_accuracy: 0.8521\n","Epoch 82/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.2917 - accuracy: 0.8655 - val_loss: 0.3225 - val_accuracy: 0.8565\n","Epoch 83/100\n","779/779 [==============================] - 66s 84ms/step - loss: 0.2815 - accuracy: 0.8691 - val_loss: 0.3076 - val_accuracy: 0.8596\n","Epoch 84/100\n","779/779 [==============================] - 66s 85ms/step - loss: 0.2762 - accuracy: 0.8714 - val_loss: 0.3003 - val_accuracy: 0.8633\n","Epoch 85/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2737 - accuracy: 0.8728 - val_loss: 0.3219 - val_accuracy: 0.8576\n","Epoch 86/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2692 - accuracy: 0.8730 - val_loss: 0.3047 - val_accuracy: 0.8627\n","Epoch 87/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.2691 - accuracy: 0.8751 - val_loss: 0.3220 - val_accuracy: 0.8547\n","Epoch 88/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2603 - accuracy: 0.8778 - val_loss: 0.2930 - val_accuracy: 0.8665\n","Epoch 89/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2563 - accuracy: 0.8787 - val_loss: 0.2959 - val_accuracy: 0.8671\n","Epoch 90/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2568 - accuracy: 0.8787 - val_loss: 0.2940 - val_accuracy: 0.8694\n","Epoch 91/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.2557 - accuracy: 0.8801 - val_loss: 0.3024 - val_accuracy: 0.8635\n","Epoch 92/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.2564 - accuracy: 0.8798 - val_loss: 0.2948 - val_accuracy: 0.8676\n","Epoch 93/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2493 - accuracy: 0.8820 - val_loss: 0.3070 - val_accuracy: 0.8653\n","Epoch 94/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2483 - accuracy: 0.8825 - val_loss: 0.2941 - val_accuracy: 0.8704\n","Epoch 95/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.2468 - accuracy: 0.8842 - val_loss: 0.3045 - val_accuracy: 0.8669\n","Epoch 96/100\n","779/779 [==============================] - 65s 83ms/step - loss: 0.2482 - accuracy: 0.8831 - val_loss: 0.3071 - val_accuracy: 0.8648\n","Epoch 97/100\n","779/779 [==============================] - 65s 84ms/step - loss: 0.2452 - accuracy: 0.8836 - val_loss: 0.2970 - val_accuracy: 0.8705\n","Epoch 98/100\n","607/779 [======================>.......] - ETA: 12s - loss: 0.2382 - accuracy: 0.8867"]}],"source":["save_path = 'transformer_multigpu_epoch_{epoch:02d}.h5'  # 或者使用你想要的保存路径\n","initial_epochs = 100\n","fine_tune_epochs = 10\n","\n","\n","\n","model1, history1, history_fine_tune1 = run_experiment(vit_classifier1, save_path, initial_epochs, fine_tune_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6EwN-YFZA-V"},"outputs":[],"source":["\n","plt.figure()\n","plt.title('Training performance')\n","plt.plot(history1.epoch, history1.history['loss'], label='train loss+error')\n","plt.plot(history1.epoch, history1.history['val_loss'], label='val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"0e68f568"},"outputs":[],"source":["from keras.layers import Activation\n","from keras.layers import Reshape\n","\n","\n","class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection_dim = projection_dim\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"num_patches\": self.num_patches,\n","            \"projection_dim\": self.projection_dim,\n","        })\n","        return config\n","\n","\n","def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    #augmented = data_augmentation(inputs)\n","    # 创建 patches.\n","    patches = Patches(patch_size)(inputs)\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # 创建Transformer层.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # 创建多头注意力机制层 multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","\n","    logits = layers.Dense(num_classes)(features)\n","\n","    layer_softmax = Activation('softmax')(logits)\n","    output = Reshape([num_classes])(layer_softmax)\n","\n","    # 创建模型.\n","    model = keras.Model(inputs=inputs, outputs=output)\n","    model.summary()\n","    #model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n","    #model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","    keras.utils.plot_model(model, to_file='graph_transformer.png', show_shapes=True)\n","    return model\n","\n","\n","def run_experiment(model, save_path, initial_epochs, fine_tune_epochs):\n","    # 第一阶段训练（初始100轮）\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=initial_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","        tf.keras.callbacks.CSVLogger('training.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,)\n","\n","    # 保存第一阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第一阶段训练的损失和准确性\n","    print(\"Phase 1 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history.history['loss'][-1], history.history['accuracy'][-1] * 100))\n","\n","    # 重新编译模型，使用 SGD 优化器和对应的学习率\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.0001), metrics=['accuracy'])\n","\n","    # 第二阶段训练（再跑100轮）\n","    history_fine_tune = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=fine_tune_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs + fine_tune_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","            tf.keras.callbacks.CSVLogger('training_fine_tune.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,\n","    )\n","\n","    # 保存第二阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs + fine_tune_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第二阶段训练的损失和准确性\n","    print(\"Phase 2 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history_fine_tune.history['loss'][-1], history_fine_tune.history['accuracy'][-1] * 100))\n","\n","    return model, history, history_fine_tune\n","\n","vit_classifier2 = create_vit_classifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"5625c8cb"},"outputs":[],"source":["save_path = 'transformer_multigpu_epoch_{epoch:02d}.h5'  # 或者使用你想要的保存路径\n","initial_epochs = 100\n","fine_tune_epochs = 10\n","\n","\n","\n","model2, history2, history_fine_tune2 = run_experiment(vit_classifier2, save_path, initial_epochs, fine_tune_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KakDVGIgGo5u"},"outputs":[],"source":["plt.figure()\n","plt.title('Training performance')\n","plt.plot(history2.epoch, history2.history['loss'], label='train loss+error')\n","plt.plot(history2.epoch, history2.history['val_loss'], label='val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9d_c3ZhGsCD"},"outputs":[],"source":["from keras.layers import Activation\n","from keras.layers import Reshape\n","\n","\n","class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection_dim = projection_dim\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"num_patches\": self.num_patches,\n","            \"projection_dim\": self.projection_dim,\n","        })\n","        return config\n","\n","\n","def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    #augmented = data_augmentation(inputs)\n","    # 创建 patches.\n","    patches = Patches(patch_size)(inputs)\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # 创建Transformer层.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # 创建多头注意力机制层 multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","\n","    logits = layers.Dense(num_classes)(features)\n","\n","    layer_softmax = Activation('softmax')(logits)\n","    output = Reshape([num_classes])(layer_softmax)\n","\n","    # 创建模型.\n","    model = keras.Model(inputs=inputs, outputs=output)\n","    model.summary()\n","    #model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n","    #model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","    keras.utils.plot_model(model, to_file='graph_transformer.png', show_shapes=True)\n","    return model\n","\n","\n","def run_experiment(model, save_path, initial_epochs, fine_tune_epochs):\n","    # 第一阶段训练（初始100轮）\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.00001), metrics=['accuracy'])\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=initial_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","        tf.keras.callbacks.CSVLogger('training.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,)\n","\n","    # 保存第一阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第一阶段训练的损失和准确性\n","    print(\"Phase 1 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history.history['loss'][-1], history.history['accuracy'][-1] * 100))\n","\n","    # 重新编译模型，使用 SGD 优化器和对应的学习率\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.00001), metrics=['accuracy'])\n","\n","    # 第二阶段训练（再跑100轮）\n","    history_fine_tune = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=fine_tune_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs + fine_tune_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","            tf.keras.callbacks.CSVLogger('training_fine_tune.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,\n","    )\n","\n","    # 保存第二阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs + fine_tune_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第二阶段训练的损失和准确性\n","    print(\"Phase 2 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history_fine_tune.history['loss'][-1], history_fine_tune.history['accuracy'][-1] * 100))\n","\n","    return model, history, history_fine_tune\n","\n","vit_classifier3 = create_vit_classifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6ngOC9xGu8Z"},"outputs":[],"source":["save_path = 'transformer_multigpu_epoch_{epoch:02d}.h5'  # 或者使用你想要的保存路径\n","initial_epochs = 100\n","fine_tune_epochs = 10\n","\n","\n","\n","model3, history3, history_fine_tune3 = run_experiment(vit_classifier3, save_path, initial_epochs, fine_tune_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-wcL3fpGsHZ"},"outputs":[],"source":["plt.figure()\n","plt.title('Training performance')\n","plt.plot(history3.epoch, history3.history['loss'], label='train loss+error')\n","plt.plot(history3.epoch, history3.history['val_loss'], label='val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eY8N4VbJHPC7"},"outputs":[],"source":["from keras.layers import Activation\n","from keras.layers import Reshape\n","\n","\n","class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection_dim = projection_dim\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"num_patches\": self.num_patches,\n","            \"projection_dim\": self.projection_dim,\n","        })\n","        return config\n","\n","\n","def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    #augmented = data_augmentation(inputs)\n","    # 创建 patches.\n","    patches = Patches(patch_size)(inputs)\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # 创建Transformer层.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # 创建多头注意力机制层 multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","\n","    logits = layers.Dense(num_classes)(features)\n","\n","    layer_softmax = Activation('softmax')(logits)\n","    output = Reshape([num_classes])(layer_softmax)\n","\n","    # 创建模型.\n","    model = keras.Model(inputs=inputs, outputs=output)\n","    model.summary()\n","    #model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n","    #model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n","    keras.utils.plot_model(model, to_file='graph_transformer.png', show_shapes=True)\n","    return model\n","\n","\n","def run_experiment(model, save_path, initial_epochs, fine_tune_epochs):\n","    # 第一阶段训练（初始100轮）\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.00001), metrics=['accuracy'])\n","    history = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=initial_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","        tf.keras.callbacks.CSVLogger('training.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,)\n","\n","    # 保存第一阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第一阶段训练的损失和准确性\n","    print(\"Phase 1 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history.history['loss'][-1], history.history['accuracy'][-1] * 100))\n","\n","    # 重新编译模型，使用 SGD 优化器和对应的学习率\n","    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.00001), metrics=['accuracy'])\n","\n","    # 第二阶段训练（再跑100轮）\n","    history_fine_tune = model.fit(\n","        x=x_train,\n","        y=y_train,\n","        batch_size=batch_size,\n","        epochs=fine_tune_epochs,\n","        validation_data=(x_valid, y_valid),\n","        callbacks=[\n","            tf.keras.callbacks.ModelCheckpoint(\n","                save_path.format(epoch=initial_epochs + fine_tune_epochs),\n","                monitor=\"val_accuracy\",\n","                save_best_only=True,\n","                save_weights_only=True,\n","                mode='max'\n","            ),\n","            tf.keras.callbacks.CSVLogger('training_fine_tune.log')  # 添加此行进行详细日志记录\n","        ],\n","        verbose=1,\n","    )\n","\n","    # 保存第二阶段训练后的模型\n","    model.save(save_path.format(epoch=initial_epochs + fine_tune_epochs) + '.keras')  # Save in native Keras format\n","\n","    # 输出第二阶段训练的损失和准确性\n","    print(\"Phase 2 - Loss: {:.4f}, Accuracy: {:.2f}%\".format(history_fine_tune.history['loss'][-1], history_fine_tune.history['accuracy'][-1] * 100))\n","\n","    return model, history, history_fine_tune\n","\n","vit_classifier4 = create_vit_classifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JhCgOfzHPKy"},"outputs":[],"source":["save_path = 'transformer_multigpu_epoch_{epoch:02d}.h5'  # 或者使用你想要的保存路径\n","initial_epochs = 100\n","fine_tune_epochs = 10\n","\n","\n","\n","model4, history4, history_fine_tune4= run_experiment(vit_classifier4, save_path, initial_epochs, fine_tune_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIb57HRdHiOE"},"outputs":[],"source":["plt.figure()\n","plt.title('Training performance')\n","plt.plot(history4.epoch, history4.history['loss'], label='train loss+error')\n","plt.plot(history4.epoch, history4.history['val_loss'], label='val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvvghOACYTfs"},"outputs":[],"source":["# 假设你已经有了model1, model2, model3的历史对象history1, history2, history3\n","plt.figure()\n","plt.title('Training performance')\n","\n","# 绘制model1的验证曲线\n","plt.plot(history1.epoch, history1.history['val_loss'], label='LR=0.001 val_error')\n","\n","# 绘制model2的验证曲线\n","plt.plot(history2.epoch, history2.history['val_loss'], label='LR=0.0001 val_error')\n","\n","# 绘制model3的验证曲线\n","plt.plot(history3.epoch, history3.history['val_loss'], label='LR=0.00001 val_error')\n","\n","#plt.plot(history4.epoch, history4.history['val_loss'], label='LR=0.00001 val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d33jVE_Di1ig"},"outputs":[],"source":["# 假设你已经有了model1, model2, model3的历史对象history1, history2, history3\n","plt.figure()\n","plt.title('Training performance')\n","\n","# 绘制model1的验证曲线\n","plt.plot(history1.epoch, history1.history['val_loss'], label='LR=0.001 val_error')\n","\n","# 绘制model2的验证曲线\n","plt.plot(history2.epoch, history2.history['val_loss'], label='LR=0.0001 val_error')\n","\n","# 绘制model3的验证曲线\n","plt.plot(history3.epoch, history3.history['val_loss'], label='LR=0.00001 val_error')\n","\n","#plt.plot(history4.epoch, history4.history['val_loss'], label='LR=0.00001 val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","# 添加坐标轴标签\n","plt.xlabel('Epoch')\n","plt.ylabel('Validation Loss')\n","\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWKY2NygzhZJ"},"outputs":[],"source":["# 假设你已经有了model1, model2, model3的历史对象history1, history2, history3\n","plt.figure(figsize=(12,6))\n","\n","# 绘制训练准确率曲线\n","plt.subplot(1, 2, 1)\n","plt.title('Training Accuracy')\n","plt.plot(history1.epoch, history1.history['accuracy'], label='LR=0.001 accuracy')\n","plt.plot(history2.epoch, history2.history['accuracy'], label='LR=0.0001 accuracy')\n","plt.plot(history3.epoch, history3.history['accuracy'], label='LR=0.00001 accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n","\n","# 绘制验证准确率曲线\n","plt.subplot(1, 2, 2)\n","plt.title('Validation Accuracy')\n","plt.plot(history1.epoch, history1.history['val_accuracy'], label='LR=0.001 val_accuracy')\n","plt.plot(history2.epoch, history2.history['val_accuracy'], label='LR=0.0001 val_accuracy')\n","plt.plot(history3.epoch, history3.history['val_accuracy'], label='LR=0.00001 val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Validation Accuracy')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DolxSiKq0gIU"},"outputs":[],"source":["# 假设你已经有了model1, model2, model3的历史对象history1, history2, history3\n","plt.figure(figsize=(12,6))\n","\n","# 绘制验证损失曲线\n","plt.subplot(1, 2, 1)\n","plt.title('Validation Loss')\n","plt.plot(history1.epoch, history1.history['val_loss'], label='LR=0.001 val_loss')\n","plt.plot(history2.epoch, history2.history['val_loss'], label='LR=0.0001 val_loss')\n","plt.plot(history3.epoch, history3.history['val_loss'], label='LR=0.00001 val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Validation Loss')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n","\n","# 绘制验证准确率曲线\n","plt.subplot(1, 2, 2)\n","plt.title('Validation Accuracy')\n","plt.plot(history1.epoch, history1.history['val_accuracy'], label='LR=0.001 val_accuracy')\n","plt.plot(history2.epoch, history2.history['val_accuracy'], label='LR=0.0001 val_accuracy')\n","plt.plot(history3.epoch, history3.history['val_accuracy'], label='LR=0.00001 val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Validation Accuracy')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYebpD7Z0ieE"},"outputs":[],"source":["# 假设你已经有了model1, model2, model3的历史对象history1, history2, history3\n","plt.figure(figsize=(12,6))\n","\n","# 绘制训练损失曲线\n","plt.subplot(1, 2, 1)\n","plt.title('Training Loss')\n","plt.plot(history1.epoch, history1.history['loss'], label='LR=0.001 train_loss')\n","plt.plot(history2.epoch, history2.history['loss'], label='LR=0.0001 train_loss')\n","plt.plot(history3.epoch, history3.history['loss'], label='LR=0.00001 train_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Loss')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n","\n","# 绘制训练准确率曲线\n","plt.subplot(1, 2, 2)\n","plt.title('Training Accuracy')\n","plt.plot(history1.epoch, history1.history['accuracy'], label='LR=0.001 train_accuracy')\n","plt.plot(history2.epoch, history2.history['accuracy'], label='LR=0.0001 train_accuracy')\n","plt.plot(history3.epoch, history3.history['accuracy'], label='LR=0.00001 train_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Accuracy')\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCYkZhRE1ABA"},"outputs":[],"source":["# 假设你已经有了model1, model2, model3的历史对象history1, history2, history3\n","plt.figure()\n","plt.title('Training performance')\n","\n","# 绘制model1的训练损失曲线\n","plt.plot(history1.epoch, history1.history['loss'], label='LR=0.001 train_loss')\n","\n","# 绘制model2的训练损失曲线\n","plt.plot(history2.epoch, history2.history['loss'], label='LR=0.0001 train_loss')\n","\n","# 绘制model3的训练损失曲线\n","plt.plot(history3.epoch, history3.history['loss'], label='LR=0.00001 train_loss')\n","\n","#plt.plot(history4.epoch, history4.history['loss'], label='LR=0.00001 train_loss')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","# 添加坐标轴标签\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Loss')\n","\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNVzNAk600Hk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2e4kLGuVfc1"},"outputs":[],"source":["\n","\n","\n","\n","plt.figure()\n","plt.title('Training performance')\n","plt.plot(history2.epoch, history2.history['loss'], label='train loss+error')\n","plt.plot(history2.epoch, history2.history['val_loss'], label='val_error')\n","\n","plt.grid(linestyle='-.')\n","plt.grid(True)\n","\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbe3b184","scrolled":false},"outputs":[],"source":["import matplotlib.pyplot as plt\n","save_path = 'transformer_multigpu_epoch_{epoch:02d}.h5'  # 或者使用你想要的保存路径\n","initial_epochs = 4\n","fine_tune_epochs = 2\n","learning_rates = [0.0001, 0.01, 0.005, 0.001, 0.0005, 0.0001,0.00001]\n","average_accuracies = []\n","\n","for lr in learning_rates:\n","    print(f\"Training with learning rate: {lr}\")\n","    # 设置学习率\n","    learning_rate = lr\n","    # 运行实验\n","    model, history, history_fine_tune = run_experiment(vit_classifier, save_path, initial_epochs, fine_tune_epochs,learning_rate)\n","    # 计算第二阶段训练后的平均准确率\n","    average_accuracy = history_fine_tune.history['accuracy'][-1]\n","    average_accuracies.append(average_accuracy)\n","\n","# 绘制学习率与平均准确率曲线\n","plt.plot(learning_rates, average_accuracies, marker='o')\n","plt.xlabel('Learning Rate')\n","plt.ylabel('Average Accuracy')\n","plt.title('Average Accuracy vs Learning Rate')\n","plt.xscale('log')  # 使用对数刻度\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bb319be"},"outputs":[],"source":["    for snr in snrs:\n","        # 获取当前SNR的测试样本和标签\n","        snr_indices = np.where(ds.Z_data == snr)[0]\n","        x_test_snr = x_test[snr_indices]\n","        y_test_snr = y_test[snr_indices]\n","\n","        # 获取模型的预测\n","        y_pred_snr = model.predict(x_test_snr)\n","        y_pred_classes_snr = np.argmax(y_pred_snr, axis=1)\n","        y_true_classes_snr = np.argmax(y_test_snr, axis=1)\n","\n","        # 计算混淆矩阵\n","        conf_mat_snr = confusion_matrix(y_true_classes_snr, y_pred_classes_snr)\n","        # 获取调制方式的实际顺序\n","        actual_modulation_order = ds.target_modulations\n","\n","        # 绘制混淆矩阵热图\n","        plt.figure(figsize=(10, 8))\n","        sns.heatmap(conf_mat_snr, annot=True, fmt='d', cmap='Blues', xticklabels=actual_modulation_order, yticklabels=actual_modulation_order)\n","        plt.xlabel('Predictive labeling')\n","        plt.ylabel('truthful labeling')\n","        plt.title(f'confusion matrix (SNR={snr})')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"276a05c5"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# 根据图像中的数据近似得到的数据\n","snr = np.array(                 [0.1, 0.01,0.001,0.0001])\n","cnn_accuracy = np.array        ([34,35,36,37])\n","#resnet_accuracy = np.array     ([0.055,  0.0554,0.0552, 0.056, 0.055,0.066,0.089,0.15,0.22, 0.30, 0.40, 0.48, 0.57, 0.65,0.72, 0.76, 0.80, 0.82, 0.82,0.82, 0.82, 0.82,   0.82,     0.82,  0.82, 0.82])\n","#transformer_accuracy = np.array([0.076,0.076,  0.078,  0.08,   0.09, 0.12, 0.18,0.25,0.32, 0.42, 0.56, 0.65, 0.71, 0.77,0.83, 0.88, 0.93, 0.95, 0.96,0.961,0.962, 0.9612,0.96132, 0.96132,0.96, 0.96])\n","# 绘制数据\n","plt.plot(snr,cnn_accuracy,label='CNN', marker='o')\n","#plt.plot(snr,resnet_accuracy,label='ResNet', marker='o')\n","#plt.plot(snr,transformer_accuracy,label='ViT', marker='o')\n","\n","# 添加标签和标题\n","plt.xlabel('SNR in dB')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy vs SNR for different models')\n","\n","# 添加图例以区分线条\n","plt.legend()\n","\n","# 显示网格\n","plt.grid(True)\n","\n","# 显示绘制的图形\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b60c161"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNUdNEtQCAb3v/jXUQmZYjN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}